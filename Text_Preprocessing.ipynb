{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# If the compiler throws ModuleNotFoundError then do a pip install\n",
        "! pip install nltk  # Natural Language Toolkit"
      ],
      "metadata": {
        "id": "GwBC4HU-827H",
        "outputId": "f53d2001-7acc-4ac2-e91c-8d8075669e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgyrvf268hHf",
        "outputId": "f44490ff-dd6c-41fe-b37c-56e88660998f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import the required libraries\n",
        "import nltk\n",
        "nltk.download('punkt_tab') #!@#$%^&*(\":>?\")\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = '''Contrary to popular belief!, Lorem Ipsum is not simply random text. It has root's in a piece of classical Latin literature from 45 BC, making it over 2000 years old!. Richard's McClintock, a Latin professor at Hampden-Sydney in Virginia, looked up one of the more obscure Latin words.'''\n",
        "\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0agqIVC9M44",
        "outputId": "2a40d18b-b00f-432a-fe29-c7ccbdbed8b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contrary to popular belief!, Lorem Ipsum is not simply random text. It has root's in a piece of classical Latin literature from 45 BC, making it over 2000 years old!. Richard's McClintock, a Latin professor at Hampden-Sydney in Virginia, looked up one of the more obscure Latin words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZATION"
      ],
      "metadata": {
        "id": "ZDOmQhqbAAg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize corpus >> document\n",
        "documents  = sent_tokenize(corpus)\n",
        "print(documents)\n",
        "print()\n",
        "\n",
        "n = 1\n",
        "for sentence in documents:\n",
        "    print(f'Document_{n}:', sentence)\n",
        "    n += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfWGzeMZ9gzY",
        "outputId": "43c6d4f5-a629-4fbd-d7df-a18b4156926f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Contrary to popular belief!, Lorem Ipsum is not simply random text.', \"It has root's in a piece of classical Latin literature from 45 BC, making it over 2000 years old!.\", \"Richard's McClintock, a Latin professor at Hampden-Sydney in Virginia, looked up one of the more obscure Latin words.\"]\n",
            "\n",
            "Document_1: Contrary to popular belief!, Lorem Ipsum is not simply random text.\n",
            "Document_2: It has root's in a piece of classical Latin literature from 45 BC, making it over 2000 years old!.\n",
            "Document_3: Richard's McClintock, a Latin professor at Hampden-Sydney in Virginia, looked up one of the more obscure Latin words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize document >> words\n",
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7VAp0Nv-6_6",
        "outputId": "1c889f97-3035-433e-aaa1-0bef47990ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Contrary', 'to', 'popular', 'belief', '!', ',', 'Lorem', 'Ipsum', 'is', 'not', 'simply', 'random', 'text', '.']\n",
            "['It', 'has', 'root', \"'s\", 'in', 'a', 'piece', 'of', 'classical', 'Latin', 'literature', 'from', '45', 'BC', ',', 'making', 'it', 'over', '2000', 'years', 'old', '!', '.']\n",
            "['Richard', \"'s\", 'McClintock', ',', 'a', 'Latin', 'professor', 'at', 'Hampden-Sydney', 'in', 'Virginia', ',', 'looked', 'up', 'one', 'of', 'the', 'more', 'obscure', 'Latin', 'words', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize corpus >> words\n",
        "word_list = word_tokenize(corpus)\n",
        "print(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4iAphsg_ob1",
        "outputId": "1cf56881-6c6f-43b0-918f-3ef0ab71099f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Contrary', 'to', 'popular', 'belief', '!', ',', 'Lorem', 'Ipsum', 'is', 'not', 'simply', 'random', 'text', '.', 'It', 'has', 'root', \"'s\", 'in', 'a', 'piece', 'of', 'classical', 'Latin', 'literature', 'from', '45', 'BC', ',', 'making', 'it', 'over', '2000', 'years', 'old', '!', '.', 'Richard', \"'s\", 'McClintock', ',', 'a', 'Latin', 'professor', 'at', 'Hampden-Sydney', 'in', 'Virginia', ',', 'looked', 'up', 'one', 'of', 'the', 'more', 'obscure', 'Latin', 'words', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEMMING"
      ],
      "metadata": {
        "id": "C0dv-pgo_8bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['programming', 'programmer', 'programs', 'programmed', 'Achieve', 'Achieving', 'enjoyment', 'enjoying', 'enjoyed',\n",
        "         'eager', 'eagerly', 'history', 'historical', 'eating', 'eaten', 'orderly', 'elderly', 'completely']"
      ],
      "metadata": {
        "id": "VlUykdebAGvA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer().stem\n",
        "for a in words:\n",
        "    print(a, '=', stemmer(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1c3i1M7AQsZ",
        "outputId": "0c240d48-d4f8-462a-a2a4-4d8eeae1faba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "programming = program\n",
            "programmer = programm\n",
            "programs = program\n",
            "programmed = program\n",
            "Achieve = achiev\n",
            "Achieving = achiev\n",
            "enjoyment = enjoy\n",
            "enjoying = enjoy\n",
            "enjoyed = enjoy\n",
            "eager = eager\n",
            "eagerly = eagerli\n",
            "history = histori\n",
            "historical = histor\n",
            "eating = eat\n",
            "eaten = eaten\n",
            "orderly = orderli\n",
            "elderly = elderli\n",
            "completely = complet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "exp_stem = RegexpStemmer('ing$|ming$|able$|ment$|ly$', min=4).stem\n",
        "for word in words:\n",
        "    print(word, '=', exp_stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrs7bRKLCPAW",
        "outputId": "640e94ae-b742-48cf-e707-69b32f2882d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "programming = program\n",
            "programmer = programmer\n",
            "programs = programs\n",
            "programmed = programmed\n",
            "Achieve = Achieve\n",
            "Achieving = Achiev\n",
            "enjoyment = enjoy\n",
            "enjoying = enjoy\n",
            "enjoyed = enjoyed\n",
            "eager = eager\n",
            "eagerly = eager\n",
            "history = history\n",
            "historical = historical\n",
            "eating = eat\n",
            "eaten = eaten\n",
            "orderly = order\n",
            "elderly = elder\n",
            "completely = complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "HzhzJ16xDnnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmas = WordNetLemmatizer().lemmatize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4oDZ7taDpkP",
        "outputId": "8c420e0d-96a9-4ecd-8692-105ce8e54405"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in words:\n",
        "    print(a, '=', lemmas(a, pos='v'))\n",
        "\n",
        "# pos ---> 'n' for nouns, 'v' for verb, 'a' for adjectives, 'r' for adverbs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdYA8cKBC8y7",
        "outputId": "5892ea3d-5cfc-4616-b0bb-ddc56ff42f74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "programming = program\n",
            "programmer = programmer\n",
            "programs = program\n",
            "programmed = program\n",
            "Achieve = Achieve\n",
            "Achieving = Achieving\n",
            "enjoyment = enjoyment\n",
            "enjoying = enjoy\n",
            "enjoyed = enjoy\n",
            "eager = eager\n",
            "eagerly = eagerly\n",
            "history = history\n",
            "historical = historical\n",
            "eating = eat\n",
            "eaten = eat\n",
            "orderly = orderly\n",
            "elderly = elderly\n",
            "completely = completely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmas('goes', pos='n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL_Ffzj7Efc-",
        "outputId": "6a78e29e-bca9-4f69-8cfc-38017bf9cdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go\n"
          ]
        }
      ]
    }
  ]
}